{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7403a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header files loaded!\n"
     ]
    }
   ],
   "source": [
    "# header files\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "print(\"Header files loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17e46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard-coded paths\n",
    "model_path = \"../epi_seg_unet.pth\"\n",
    "image_path = \"../data/TCGA-23-1123_5.png\"\n",
    "output_path = \"../results/mask_5.png\"\n",
    "device = \"cpu\"\n",
    "patch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e8d8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "# apply segmentation model on a patch\n",
    "def get_patch_segmentation(patch):\n",
    "    # resize and normalize the patch\n",
    "    patch = patch.transpose((2, 0, 1))\n",
    "    patch = patch / 255\n",
    "    \n",
    "    # convert patch to tensor\n",
    "    patch = torch.from_numpy(patch)\n",
    "    patch = patch.unsqueeze(0)\n",
    "    patch = patch.to(device, dtype=torch.float32)\n",
    "    patch_output = net(patch)\n",
    "    \n",
    "    # convert the patch output to binary mask\n",
    "    patch_output = torch.sigmoid(patch_output)\n",
    "    patch_output = patch_output.detach().squeeze().cpu().numpy()\n",
    "    patch_output = (patch_output>.5).astype(np.uint8)\n",
    "    \n",
    "    # return mask for the patch\n",
    "    return patch_output\n",
    "\n",
    "\n",
    "# update main output from patch segmentation output\n",
    "def update_output(patch_output, patch_dims):\n",
    "    for index1 in range(0, patch_output.shape[0]):\n",
    "        for index2 in range(0, patch_output.shape[1]):\n",
    "            output[patch_dims[0]+index1, patch_dims[1]+index2] = patch_output[index1, index2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d096cd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "# read image and apply transforms\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = image.resize((512, 512), Image.BICUBIC)\n",
    "image = np.array(image).astype(np.uint8)\n",
    "image = image.transpose((2, 0, 1))\n",
    "image = image / 255\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5979de2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (inc): DoubleConv(\n",
      "    (double_conv): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (down1): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down2): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down3): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down4): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up1): Up(\n",
      "    (up): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up2): Up(\n",
      "    (up): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up3): Up(\n",
      "    (up): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up4): Up(\n",
      "    (up): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (outc): OutConv(\n",
      "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arpitdec5/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/arpitdec5/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/arpitdec5/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/arpitdec5/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/arpitdec5/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/arpitdec5/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.conv.ConvTranspose2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "net = torch.load(model_path, map_location=device)\n",
    "net.eval()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f78b187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arpitdec5/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/Users/arpitdec5/opt/anaconda3/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "image = torch.from_numpy(image)\n",
    "image = image.unsqueeze(0)\n",
    "image = image.to(device, dtype=torch.float32)\n",
    "image_output = net(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672b9c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate masks for each patch of the tile\n",
    "output = np.zeros((image.shape[0], image.shape[1]))\n",
    "output = np.array(output).astype(np.uint8)\n",
    "for index1 in range(0, image.shape[0], patch_size):\n",
    "    for index2 in range(0, image.shape[1], patch_size):\n",
    "        patch_output = get_patch_segmentation(image[index1:min(index1+patch_size, image.shape[0]), index2:min(index2+patch_size, image.shape[1])])\n",
    "        update_output(patch_output, (index1, index2))\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b829dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image\n",
    "image_output = torch.sigmoid(image_output)\n",
    "image_output = image_output.detach().squeeze().cpu().numpy()\n",
    "image_output = (image_output>.5).astype(np.uint8)\n",
    "image_output = Image.fromarray((image_output*255).astype(np.uint8))\n",
    "image_output = image_output.resize((2000, 2000), Image.BICUBIC)\n",
    "image_output.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4559e735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "mask = cv2.imread(\"../results/epithelium_stroma_masks/TCGA-23-1123_21000_12000_epi_stroma_mask.png\", 0)\n",
    "ret, mask = cv2.threshold(mask, 200, 255, cv2.THRESH_BINARY)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c498f5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150.4755\n"
     ]
    }
   ],
   "source": [
    "epi_value = float(sum([sum(i) for i in mask])) / float(mask.shape[0]*mask.shape[1])\n",
    "print(epi_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9061a980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.5245\n"
     ]
    }
   ],
   "source": [
    "mask = 255. - mask\n",
    "stroma_value = float(sum([sum(i) for i in mask])) / float(mask.shape[0]*mask.shape[1])\n",
    "print(stroma_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43ba6a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[255, 255, 255], [255, 255, 255], [255, 255, 255]])\n",
    "print(sum(sum(255. - a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26de7d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104524500.0\n"
     ]
    }
   ],
   "source": [
    "print(float(sum([sum(i) for i in mask])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d07b2063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409900\n",
      "590100\n"
     ]
    }
   ],
   "source": [
    "count1 = 0\n",
    "count2 = 0\n",
    "for index1 in range(0, 1000):\n",
    "    for index2 in range(0, 1000):\n",
    "        if mask[index1, index2] == 0:\n",
    "            count1 += 1\n",
    "        if mask[index1, index2] == 255:\n",
    "            count2 += 1\n",
    "print(count1)\n",
    "print(count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf46e2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
